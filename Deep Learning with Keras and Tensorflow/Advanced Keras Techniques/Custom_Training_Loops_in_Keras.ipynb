{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dogukartal/IBM_AI_Labs/blob/main/Deep%20Learning%20with%20Keras%20and%20Tensorflow/Advanced%20Keras%20Techniques/Custom_Training_Loops_in_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "728f25e0-fb12-49a0-a9cb-88312e48f5bf",
        "outputId": "87df7bcc-f183-45bf-8ba0-367be88caba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)"
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9ecb75e-7548-464d-bf40-d7bbff1a64e2",
        "outputId": "86048ecc-c0ce-41a5-c70b-151b1ce9fc4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10)\n",
        "])"
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb5839c9-2bc1-41bd-a0cd-8b1fe65f2c7f"
      },
      "outputs": [],
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80afaf2c-1e40-4146-8672-d1b59b32ed91",
        "outputId": "94c18149-d714-4d44-8ee2-35ed3feac6e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of epoch 1\n",
            "Epoch 1 Step 0: Loss = 2.3397436141967773\n",
            "Epoch 1 Step 200: Loss = 0.3975307047367096\n",
            "Epoch 1 Step 400: Loss = 0.1745842844247818\n",
            "Epoch 1 Step 600: Loss = 0.1918162852525711\n",
            "Epoch 1 Step 800: Loss = 0.1540633589029312\n",
            "Epoch 1 Step 1000: Loss = 0.4290245771408081\n",
            "Epoch 1 Step 1200: Loss = 0.15897470712661743\n",
            "Epoch 1 Step 1400: Loss = 0.314909964799881\n",
            "Epoch 1 Step 1600: Loss = 0.2296106219291687\n",
            "Epoch 1 Step 1800: Loss = 0.1967483013868332\n",
            "Start of epoch 2\n",
            "Epoch 2 Step 0: Loss = 0.06299980729818344\n",
            "Epoch 2 Step 200: Loss = 0.13888703286647797\n",
            "Epoch 2 Step 400: Loss = 0.10344912111759186\n",
            "Epoch 2 Step 600: Loss = 0.07110658288002014\n",
            "Epoch 2 Step 800: Loss = 0.09432362020015717\n",
            "Epoch 2 Step 1000: Loss = 0.30628857016563416\n",
            "Epoch 2 Step 1200: Loss = 0.08869801461696625\n",
            "Epoch 2 Step 1400: Loss = 0.15422971546649933\n",
            "Epoch 2 Step 1600: Loss = 0.16261371970176697\n",
            "Epoch 2 Step 1800: Loss = 0.152454674243927\n"
          ]
        }
      ],
      "source": [
        "epochs = 2\n",
        "# train_dataset = train_dataset.repeat(epochs)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
        "for epoch in range(epochs):\n",
        "    print(f'Start of epoch {epoch + 1}')\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch_train, training=True)  # Forward pass\n",
        "            loss_value = loss_fn(y_batch_train, logits)  # Compute loss\n",
        "\n",
        "        # Compute gradients and update weights\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "        # Logging the loss every 200 steps\n",
        "        if step % 200 == 0:\n",
        "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()}')\n"
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric Tracking:"
      ],
      "metadata": {
        "id": "xf-mCWQCqR_n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7263943a-fcaf-4b16-b24c-25f80911fe78",
        "outputId": "b9bde737-ad08-43fd-f430-8023d421aff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of epoch 1\n",
            "Epoch 1 Step 0: Loss = 2.4198756217956543 Accuracy = 0.03125\n",
            "Epoch 1 Step 200: Loss = 0.4390305280685425 Accuracy = 0.8351989984512329\n",
            "Epoch 1 Step 400: Loss = 0.1864641308784485 Accuracy = 0.8692331910133362\n",
            "Epoch 1 Step 600: Loss = 0.1956380307674408 Accuracy = 0.8838394284248352\n",
            "Epoch 1 Step 800: Loss = 0.1622450351715088 Accuracy = 0.8962234854698181\n",
            "Epoch 1 Step 1000: Loss = 0.39944636821746826 Accuracy = 0.9033466577529907\n",
            "Epoch 1 Step 1200: Loss = 0.18639424443244934 Accuracy = 0.910205066204071\n",
            "Epoch 1 Step 1400: Loss = 0.22900953888893127 Accuracy = 0.9151498675346375\n",
            "Epoch 1 Step 1600: Loss = 0.2342425435781479 Accuracy = 0.9182347059249878\n",
            "Epoch 1 Step 1800: Loss = 0.20682409405708313 Accuracy = 0.9223521947860718\n",
            "Start of epoch 2\n",
            "Epoch 2 Step 0: Loss = 0.10627587139606476 Accuracy = 0.96875\n",
            "Epoch 2 Step 200: Loss = 0.14226771891117096 Accuracy = 0.9617537260055542\n",
            "Epoch 2 Step 400: Loss = 0.08507358282804489 Accuracy = 0.9600217938423157\n",
            "Epoch 2 Step 600: Loss = 0.04531487450003624 Accuracy = 0.9618344306945801\n",
            "Epoch 2 Step 800: Loss = 0.08275990188121796 Accuracy = 0.9626638293266296\n",
            "Epoch 2 Step 1000: Loss = 0.2547434866428375 Accuracy = 0.9628496766090393\n",
            "Epoch 2 Step 1200: Loss = 0.11736336350440979 Accuracy = 0.9636760950088501\n",
            "Epoch 2 Step 1400: Loss = 0.11330283433198929 Accuracy = 0.9643558263778687\n",
            "Epoch 2 Step 1600: Loss = 0.1649373173713684 Accuracy = 0.964377760887146\n",
            "Epoch 2 Step 1800: Loss = 0.09670083969831467 Accuracy = 0.9651755690574646\n",
            "Start of epoch 3\n",
            "Epoch 3 Step 0: Loss = 0.0522465780377388 Accuracy = 0.96875\n",
            "Epoch 3 Step 200: Loss = 0.10898058861494064 Accuracy = 0.9751243591308594\n",
            "Epoch 3 Step 400: Loss = 0.05242329090833664 Accuracy = 0.9745168089866638\n",
            "Epoch 3 Step 600: Loss = 0.04140527546405792 Accuracy = 0.9750936031341553\n",
            "Epoch 3 Step 800: Loss = 0.04691644757986069 Accuracy = 0.9754213690757751\n",
            "Epoch 3 Step 1000: Loss = 0.16124387085437775 Accuracy = 0.9755868911743164\n",
            "Epoch 3 Step 1200: Loss = 0.10328127443790436 Accuracy = 0.975775420665741\n",
            "Epoch 3 Step 1400: Loss = 0.0568600669503212 Accuracy = 0.9759546518325806\n",
            "Epoch 3 Step 1600: Loss = 0.09781172126531601 Accuracy = 0.9759134650230408\n",
            "Epoch 3 Step 1800: Loss = 0.05813288688659668 Accuracy = 0.9764540791511536\n",
            "Start of epoch 4\n",
            "Epoch 4 Step 0: Loss = 0.04688047617673874 Accuracy = 0.96875\n",
            "Epoch 4 Step 200: Loss = 0.056446392089128494 Accuracy = 0.9825870394706726\n",
            "Epoch 4 Step 400: Loss = 0.038090988993644714 Accuracy = 0.9816084504127502\n",
            "Epoch 4 Step 600: Loss = 0.03544304147362709 Accuracy = 0.981853187084198\n",
            "Epoch 4 Step 800: Loss = 0.03110470063984394 Accuracy = 0.9818196296691895\n",
            "Epoch 4 Step 1000: Loss = 0.12107667326927185 Accuracy = 0.9820492267608643\n",
            "Epoch 4 Step 1200: Loss = 0.09047829359769821 Accuracy = 0.9823324084281921\n",
            "Epoch 4 Step 1400: Loss = 0.02565157413482666 Accuracy = 0.9825124740600586\n",
            "Epoch 4 Step 1600: Loss = 0.05354919657111168 Accuracy = 0.9821205735206604\n",
            "Epoch 4 Step 1800: Loss = 0.0548766627907753 Accuracy = 0.9826138019561768\n",
            "Start of epoch 5\n",
            "Epoch 5 Step 0: Loss = 0.059015754610300064 Accuracy = 0.96875\n",
            "Epoch 5 Step 200: Loss = 0.03505506366491318 Accuracy = 0.9870957732200623\n",
            "Epoch 5 Step 400: Loss = 0.04236181452870369 Accuracy = 0.9862843155860901\n",
            "Epoch 5 Step 600: Loss = 0.04143572598695755 Accuracy = 0.9865328669548035\n",
            "Epoch 5 Step 800: Loss = 0.02196604013442993 Accuracy = 0.9865792989730835\n",
            "Epoch 5 Step 1000: Loss = 0.0908510684967041 Accuracy = 0.9868568778038025\n",
            "Epoch 5 Step 1200: Loss = 0.04985736310482025 Accuracy = 0.9871200919151306\n",
            "Epoch 5 Step 1400: Loss = 0.015062764286994934 Accuracy = 0.9870851039886475\n",
            "Epoch 5 Step 1600: Loss = 0.0301962997764349 Accuracy = 0.9869807958602905\n",
            "Epoch 5 Step 1800: Loss = 0.04422583431005478 Accuracy = 0.9873160719871521\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),  # Flatten the input to a 1D vector\n",
        "    Dense(128, activation='relu'),  # First hidden layer with 128 neurons and ReLU activation\n",
        "    Dense(10)  # Output layer with 10 neurons for the 10 classes (digits 0-9)\n",
        "])\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Loss function for multi-class classification\n",
        "optimizer = tf.keras.optimizers.Adam()  # Adam optimizer for efficient training\n",
        "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()  # Metric to track accuracy during training\n",
        "\n",
        "epochs = 5  # Number of epochs for training\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Start of epoch {epoch + 1}')\n",
        "\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass: Compute predictions\n",
        "            logits = model(x_batch_train, training=True)\n",
        "            # Compute loss\n",
        "            loss_value = loss_fn(y_batch_train, logits)\n",
        "\n",
        "        # Compute gradients\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        # Apply gradients to update model weights\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "        # Update the accuracy metric\n",
        "        accuracy_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "        # Log the loss and accuracy every 200 steps\n",
        "        if step % 200 == 0:\n",
        "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()} Accuracy = {accuracy_metric.result().numpy()}')\n",
        "\n",
        "    # Reset the metric at the end of each epoch\n",
        "    accuracy_metric.reset_state()"
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aad4044-971c-4c8d-bd28-d8fc21cdaba5"
      },
      "source": [
        "### Custom Callback for Advanced Logging:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7322571-c9f4-4ecb-b57a-a2051660692f",
        "outputId": "1b955496-3e91-487f-b533-16f5a0204605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of epoch 1\n",
            "Epoch 1 Step 0: Loss = 2.3084664344787598 Accuracy = 0.125\n",
            "Epoch 1 Step 200: Loss = 0.35844916105270386 Accuracy = 0.8392412662506104\n",
            "Epoch 1 Step 400: Loss = 0.19218559563159943 Accuracy = 0.8700904250144958\n",
            "Epoch 1 Step 600: Loss = 0.18993523716926575 Accuracy = 0.8847233653068542\n",
            "Epoch 1 Step 800: Loss = 0.16905711591243744 Accuracy = 0.8968086838722229\n",
            "Epoch 1 Step 1000: Loss = 0.42028942704200745 Accuracy = 0.903377890586853\n",
            "Epoch 1 Step 1200: Loss = 0.22590279579162598 Accuracy = 0.9097887277603149\n",
            "Epoch 1 Step 1400: Loss = 0.19921763241291046 Accuracy = 0.9147930145263672\n",
            "Epoch 1 Step 1600: Loss = 0.25706884264945984 Accuracy = 0.9181370735168457\n",
            "Epoch 1 Step 1800: Loss = 0.21855886280536652 Accuracy = 0.9221439361572266\n",
            "End of epoch 1, loss: 0.028156643733382225, accuracy: 0.9239166378974915\n",
            "Start of epoch 2\n",
            "Epoch 2 Step 0: Loss = 0.07987038791179657 Accuracy = 1.0\n",
            "Epoch 2 Step 200: Loss = 0.17161650955677032 Accuracy = 0.9628420472145081\n",
            "Epoch 2 Step 400: Loss = 0.11246950924396515 Accuracy = 0.9593204259872437\n",
            "Epoch 2 Step 600: Loss = 0.04712831228971481 Accuracy = 0.9604305028915405\n",
            "Epoch 2 Step 800: Loss = 0.07336989790201187 Accuracy = 0.9617665410041809\n",
            "Epoch 2 Step 1000: Loss = 0.27967801690101624 Accuracy = 0.9618818759918213\n",
            "Epoch 2 Step 1200: Loss = 0.12365753948688507 Accuracy = 0.9626873731613159\n",
            "Epoch 2 Step 1400: Loss = 0.12110496312379837 Accuracy = 0.9636866450309753\n",
            "Epoch 2 Step 1600: Loss = 0.20158153772354126 Accuracy = 0.9638311862945557\n",
            "Epoch 2 Step 1800: Loss = 0.11998535692691803 Accuracy = 0.9644815325737\n",
            "End of epoch 2, loss: 0.03514150530099869, accuracy: 0.9650833606719971\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class CustomCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        print(f'End of epoch {epoch + 1}, loss: {logs.get(\"loss\")}, accuracy: {logs.get(\"accuracy\")}')\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),  # Flatten the input to a 1D vector\n",
        "    Dense(128, activation='relu'),  # First hidden layer with 128 neurons and ReLU activation\n",
        "    Dense(10)  # Output layer with 10 neurons for the 10 classes (digits 0-9)\n",
        "])\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Loss function for multi-class classification\n",
        "optimizer = tf.keras.optimizers.Adam()  # Adam optimizer for efficient training\n",
        "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()  # Metric to track accuracy during training\n",
        "\n",
        "epochs = 2\n",
        "custom_callback = CustomCallback()  # Initialize the custom callback\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Start of epoch {epoch + 1}')\n",
        "\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass: Compute predictions\n",
        "            logits = model(x_batch_train, training=True)\n",
        "            # Compute loss\n",
        "            loss_value = loss_fn(y_batch_train, logits)\n",
        "\n",
        "        # Compute gradients\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        # Apply gradients to update model weights\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "        # Update the accuracy metric\n",
        "        accuracy_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "        # Log the loss and accuracy every 200 steps\n",
        "        if step % 200 == 0:\n",
        "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()} Accuracy = {accuracy_metric.result().numpy()}')\n",
        "\n",
        "    # Call the custom callback at the end of each epoch\n",
        "    custom_callback.on_epoch_end(epoch, logs={'loss': loss_value.numpy(), 'accuracy': accuracy_metric.result().numpy()})\n",
        "\n",
        "    # Reset the metric at the end of each epoch\n",
        "    accuracy_metric.reset_state()  # Use reset_state() instead of reset_states()"
      ],
      "execution_count": 6
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "prev_pub_hash": "48a1eb2565c8b635156cd21708473ccadb84e292e93f3530a9d5223b7590344e",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}