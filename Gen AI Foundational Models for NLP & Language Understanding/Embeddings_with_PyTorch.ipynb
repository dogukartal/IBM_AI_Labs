{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOf2hqCDTrLnJq6fh938zCS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dogukartal/IBM_AI_Labs/blob/main/Gen%20AI%20Foundational%20Models%20for%20NLP%20%26%20Language%20Understanding/Embeddings_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings\n",
        "---"
      ],
      "metadata": {
        "id": "-eSqLyD5nep6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqq torch==2.3.0\n",
        "!pip install -Uqq torchtext==0.18.0\n",
        "!pip install -Uqq spacy\n",
        "!python -m spacy download en_core_web_sm -qq"
      ],
      "metadata": {
        "id": "c4aDKpYShWz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "uDw1wvybjDvH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyqKih3sgW5p",
        "outputId": "8382b571-d07f-45e2-b709-6a81f41ece4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dataset = [\"I like cats\", \"I hate dogs\", \"I'm impartial to hippos\"]\n",
        "\n",
        "tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "  for data_sample in data_iter:\n",
        "    yield tokenizer(data_sample)\n",
        "\n",
        "data_iter = iter(dataset)\n",
        "\n",
        "# Creating the vocab\n",
        "vocab = build_vocab_from_iterator(yield_tokens(data_iter))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[\"like\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HjcbUBMkntg",
        "outputId": "6b5b742f-6496-4233-d297-7546ed79e488"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning IDs to tokens\n",
        "input_ids = lambda x:[torch.tensor(vocab(tokenizer(data_sample))) for data_sample in dataset]\n",
        "\n",
        "index = input_ids(dataset)\n",
        "print(index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wodiqGllnou",
        "outputId": "38cf7baa-f233-40a4-beca-c7c68e63249a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([0, 7, 2]), tensor([0, 4, 3]), tensor([0, 1, 6, 8, 5])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Layer"
      ],
      "metadata": {
        "id": "PRsCc_ZPnh2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Embedding Layer\n",
        "embedding_dim = 3\n",
        "\n",
        "num_embeddings = len(vocab)\n",
        "\n",
        "embeds = nn.Embedding(num_embeddings, embedding_dim)\n",
        "print(embeds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBaS639Vl8-G",
        "outputId": "16b07c3e-3253-4832-f8d3-fef3fb7a6c8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(9, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the Embedding to First Sentence\n",
        "i_like_cats = embeds(index[0])\n",
        "i_like_cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p58YddFDm1Fs",
        "outputId": "6ada4684-b58b-420e-c05a-3814c18ee452"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5457,  0.9364,  0.0987],\n",
              "        [-0.8796, -1.6541,  0.4330],\n",
              "        [ 1.7350, -1.1639, -1.1612]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Bag Layer"
      ],
      "metadata": {
        "id": "VBwZuurWnz1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Embedding Bag Layer\n",
        "embedding_bag = nn.EmbeddingBag(num_embeddings, embedding_dim)\n",
        "print(embedding_bag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njv61CaHnOwN",
        "outputId": "d015f45e-6df7-4fed-a104-3042068cf3dd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmbeddingBag(9, 3, mode='mean')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i_like_cats = embedding_bag(index[0], offsets=torch.tensor([0]))\n",
        "i_like_cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfr4tF1Hn8T8",
        "outputId": "f6489b39-afa2-43bd-af1d-0d89b3d63140"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6630,  0.8253,  0.3493]], grad_fn=<EmbeddingBagBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Embedding Bag to multiple Samples\n",
        "index_flat = torch.cat(index)\n",
        "print(index_flat)\n",
        "\n",
        "offset = [len(sample) for sample in index]\n",
        "offset.insert(0, 0)\n",
        "offset = torch.cumsum(torch.tensor(offset), 0)[0:-1]\n",
        "\n",
        "i_like_cats = embedding_bag(index_flat, offsets=offset)\n",
        "i_like_cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJIj1tZPoIYl",
        "outputId": "0b91efed-0f00-4e28-c7c9-6ab7cf0e1ec1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 7, 2, 0, 4, 3, 0, 1, 6, 8, 5])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6630,  0.8253,  0.3493],\n",
              "        [-0.5844, -0.1395,  0.4568],\n",
              "        [ 0.1389,  0.2569, -0.4592]], grad_fn=<EmbeddingBagBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}