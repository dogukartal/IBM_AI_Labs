{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dogukartal/IBM_AI_Labs/blob/main/Generative%20AI%20Language%20Modeling%20with%20Transformers/Transformer_Model_for_Language_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8422ffd2-3570-4d01-b433-1bd22c3181ed"
      },
      "source": [
        "# A Transformer Model for Language Translation\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b700ad5a-9473-4263-ab77-a20a6eb78a32"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "196980bf-7d1b-4557-a6ee-d53686d74b4b"
      },
      "outputs": [],
      "source": [
        "!pip install -qq torch==2.0.0\n",
        "!pip install -qq torchtext==0.15.1\n",
        "!pip install -qq torchdata==0.6.0\n",
        "!pip install -U spacy==3.7.2\n",
        "!pip install -Uqq portalocker==2.7.0\n",
        "!pip install -Uq nltk==3.8.1\n",
        "\n",
        "!python -m spacy download de\n",
        "!python -m spacy download en\n",
        "\n",
        "!pip install pdfplumber==0.9.0\n",
        "!pip install fpdf==1.7.2\n",
        "\n",
        "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Multi30K_de_en_dataloader.py'\n",
        "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/transformer.pt'\n",
        "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/input_de.pdf'"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b4eecc2-730e-45a9-88d4-f2996a3a3355"
      },
      "source": [
        "## Importing required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8da731fc-8632-4fa0-9dd3-590fdf944f73"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import multi30k, Multi30k\n",
        "import torch\n",
        "from typing import Iterable, List\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "# You can also use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29f1003f-3410-4ddc-b2ad-8c1a8d39542f"
      },
      "outputs": [],
      "source": [
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73bb7562-5058-4dd7-9eba-f9db14f91e96",
        "outputId": "5a7f5569-e32f-469b-ab20-4b014535065f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecb57794-884e-4030-88be-31fb79951383"
      },
      "source": [
        "## DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be2d2b30-0ac3-479c-b4fb-0b9dd2e9a987"
      },
      "outputs": [],
      "source": [
        "%run Multi30K_de_en_dataloader.py"
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59207cbd-f08d-4fb6-99b8-94ebd96a6036",
        "outputId": "e017e3b6-adb1-4682-d26f-2fab1c26fefb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x79c2eabdded0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_dataloader, _ = get_translation_dataloaders(batch_size = 1)\n",
        "data_itr = iter(train_dataloader)\n",
        "data_itr"
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a270bde-eb55-43e3-9fe2-a0cd99533af5"
      },
      "outputs": [],
      "source": [
        "# Examples\n",
        "for n in range(1000):\n",
        "    german, english = next(data_itr)"
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39e64c9d-67cc-47dd-a869-5282b782a74e"
      },
      "outputs": [],
      "source": [
        "# Change the data structure from sequence-batch-feature to batch-feature-sequence\n",
        "german = german.T\n",
        "english = english.T"
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35b158cd-1d14-4651-9b3f-50e2d9d8f54a",
        "outputId": "260b11a3-43fa-4ee4-f041-66d0e7c24aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample 0\n",
            "german input\n",
            "<bos> Ein Feuerwehrangehöriger arbeitet bei einem Brand . <eos>\n",
            "english target\n",
            "<bos> A firefighter is working at a fire . <eos>\n",
            "_________\n",
            "\n",
            "sample 1\n",
            "german input\n",
            "<bos> Ein Mann spielt auf einem Flügel . <eos>\n",
            "english target\n",
            "<bos> A man playing a black grand piano . <eos>\n",
            "_________\n",
            "\n",
            "sample 2\n",
            "german input\n",
            "<bos> Ein brauner Hund spielt im Schnee . <eos>\n",
            "english target\n",
            "<bos> A brown dog plays in the snow . <eos>\n",
            "_________\n",
            "\n",
            "sample 3\n",
            "german input\n",
            "<bos> Mehrere Hunde in einem winterlichen Ambiente . <eos>\n",
            "english target\n",
            "<bos> Several dogs grouped together in a winter setting . <eos>\n",
            "_________\n",
            "\n",
            "sample 4\n",
            "german input\n",
            "<bos> Ein Mann klettert einen Felsen hoch . <eos>\n",
            "english target\n",
            "<bos> A man climbs up a rock . <eos>\n",
            "_________\n",
            "\n",
            "sample 5\n",
            "german input\n",
            "<bos> Zwei Teams kämpfen um den Sieg . <eos>\n",
            "english target\n",
            "<bos> Two teams battle it out for the win ! <eos>\n",
            "_________\n",
            "\n",
            "sample 6\n",
            "german input\n",
            "<bos> Kinder spielen in einem aufblasbaren Spielplatz . <eos>\n",
            "english target\n",
            "<bos> Kids play in a blow up playground . <eos>\n",
            "_________\n",
            "\n",
            "sample 7\n",
            "german input\n",
            "<bos> Ein kleiner Junge malt einen Teller . <eos>\n",
            "english target\n",
            "<bos> A little boy is paining a plate . <eos>\n",
            "_________\n",
            "\n",
            "sample 8\n",
            "german input\n",
            "<bos> Die beiden Frauen blicken auf etwas . <eos>\n",
            "english target\n",
            "<bos> The two woman are looking at something . <eos>\n",
            "_________\n",
            "\n",
            "sample 9\n",
            "german input\n",
            "<bos> Fünf Kricketspieler liegen auf dem Gras . <eos>\n",
            "english target\n",
            "<bos> Five cricket players are lounging on the grass . <eos>\n",
            "_________\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Converting indexes to words\n",
        "for n in range(10):\n",
        "    german, english = next(data_itr)\n",
        "    print(\"sample {}\".format(n))\n",
        "    print(\"german input\")\n",
        "    print(index_to_german(german))\n",
        "    print(\"english target\")\n",
        "    print(index_to_eng(english))\n",
        "    print(\"_________\\n\")"
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b502b460-0a2d-48e0-92db-37601c36dced"
      },
      "source": [
        "## Functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86b60ebd-1ce9-46d7-bc26-3b37d5af8b04"
      },
      "source": [
        "### Masking\n",
        "\n",
        "During training, the entire sequence is visible to the model and used as input to learn patterns. In contrast, for prediction, the future sequence is not available. To do this, employ masking to simulate this lack of future data, ensuring the model learns to predict without seeing the actual next tokens. It is crucial for ensuring certain positions are not attended to. The function ```generate_square_subsequent_mask``` produces an upper triangular matrix, which ensures that during decoding, a token can't attend to future tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c9a2c8f-9330-4e18-9aaa-196fbbe0f303"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz, device=DEVICE):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask"
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e709fd42-6e6d-4112-b840-a46fe1701c25"
      },
      "source": [
        "The ```create_mask``` function, on the other hand, generates both source and target masks, as well as padding masks based on the provided source and target sequences. The padding masks ensure that the model doesn't attend to pad tokens, providing a streamlined attention.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7029b7f5-7bc9-474c-bab0-d992a11efd37"
      },
      "outputs": [],
      "source": [
        "def create_mask(src, tgt,device=DEVICE):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a2d64b5-0d11-431b-a56a-6d94ce8bb738"
      },
      "source": [
        "### Positional encoding\n",
        "The transformer model doesn't have built-in knowledge of the order of tokens in the sequence. To give the model this information, positional encodings are added to the tokens embeddings. These encodings have a fixed pattern based on their position in the sequence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59bd3cdc-4120-4478-acde-2802b02a7be0"
      },
      "outputs": [],
      "source": [
        "# Add positional information to the input tokens\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "929979c6-2f02-4aa8-93d9-3f2f473bd800"
      },
      "source": [
        "### Token embedding\n",
        "Token embedding, also known as word embedding or word representation, is a way to convert words or tokens from a text corpus into numerical vectors in a continuous vector space. Each unique word or token in the corpus is assigned a fixed-length vector where the numerical values represent various linguistic properties of the word, such as its meaning, context, or relationships with other words.\n",
        "\n",
        "The `TokenEmbedding` class below converts numerical tokens into embeddings:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bfbeb53-4580-42a6-af70-132d7bbd37ba"
      },
      "outputs": [],
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "078bcc32-286b-4bef-bc8f-85d3ea0cfff0"
      },
      "source": [
        "## Transformer architecture for language translation\n",
        "### Tokenization and positional encoding\n",
        "To begin, source language text (the input sequence) is tokenized, which means it's divided into individual words or subwords. These tokens are then converted into numerical representations. To preserve word order information, positional encodings are added to these numerical tokens.\n",
        "\n",
        "### Encoder processing\n",
        "The next step involves passing these numerical tokens through the encoder. The encoder is composed of multiple layers, each containing self-attention mechanisms and feed-forward neural networks. This architecture allows the transformer model to process the entire input sequence at once, in contrast to traditional RNN-based models like LSTMs or GRUs, which process input sequentially.\n",
        "\n",
        "### Decoding with teacher forcing\n",
        "During training, the target language text (the correct output sequence) is also tokenized and converted into numerical tokens. \"Teacher forcing\" is a training technique where the decoder is provided with the target tokens as input. The decoder uses both the encoder's output and the previously generated tokens (starting with a special start-of-sequence token) to predict the next token in the sequence.\n",
        "\n",
        "### Output generation and loss calculation\n",
        "The decoder generates the translated sequence token by token. At each step, the decoder predicts the next token in the target sequence. The predicted sequence from the decoder is then compared to the actual target sequence using a loss function, typically cross-entropy loss for translation tasks. This loss function quantifies how well the model's predictions match the true target sequence.\n",
        "\n",
        "## Seq2SeqTransformer\n",
        "- **Data loading:** Loading and preparing the training data, which includes source language text and corresponding target language text.\n",
        "\n",
        "- **Model initialization:** Initializing the transformer model, including setting up the encoder, decoder, positional encodings, and other necessary components.\n",
        "\n",
        "- **Optimizer setup:** Choosing an appropriate optimizer, such as Adam, and defining learning rate schedules to update model parameters during training.\n",
        "\n",
        "- **Training loop:** Iterating through the training data for multiple epochs, using teacher forcing to guide the model's learning process.\n",
        "\n",
        "- **Loss monitoring:** Recording and potentially plotting training losses for each epoch. These losses indicate how well the model is learning to perform language translation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9341d74a-e36e-4ca0-8287-9a028eec1d8c"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        outs =outs.to(DEVICE)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "278394d6-9e49-4c70-b8b8-3ce5b4a45643"
      },
      "source": [
        "## Inference\n",
        "\n",
        "\n",
        "The diagram below illustrates the sequence prediction or inference process. You can begin by feeding the indices of your desired translation sequence into the encoder, represented by the lower-left orange section. The resulting embeddings from the encoder are then channeled into the decoder, highlighted in green. Alongside, a start token is introduced at the beginning of the decoder input, as depicted at the base of the green segment.\n",
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/predict_transformers.png\" alt=\"transformer\">\n",
        "The decoder's output is then mapped onto a vocabulary-sized vector using a linear layer. Following this, a softmax function converts these vector scores into probabilities. The highest probability, as determined by the argmax function, provides the index of your predicted word within the translated sequence. This predicted index is fed back into the decoder in conjunction with the initial sequence, setting the stage to determine the subsequent word in the translation. This autoregressive process is demonstrated by the arrow pointing to form the top of the decoder, in green, to the bottom.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efa40cb4-c0fa-4928-be36-9743d92f5200"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)"
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trained Model"
      ],
      "metadata": {
        "id": "1PCDvpz4ZtR6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "387ee0a7-0fbb-4000-bfb0-22df6caf1e65",
        "outputId": "91085cad-0d88-4c5a-fb35-baeb864942fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "transformer.load_state_dict(torch.load('transformer.pt', map_location=DEVICE, ))"
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16617746-32bb-4b97-95cf-9d19f55e1039"
      },
      "source": [
        "Since your dataset is organized by sequence length, let's iterate through it to obtain a longer sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3daa8db3-0a69-4e7e-9d72-6bbb05b6aab6"
      },
      "outputs": [],
      "source": [
        "for n in range(100):\n",
        "    src ,tgt= next(data_itr)"
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad1cfb28-0ad0-4894-bd03-e8bc51cfeb88"
      },
      "source": [
        "Display the source sequence in German that you aim to translate, alongside the target sequence in English that you want your model to produce\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8464afe-defa-4082-93a8-de9082937c86",
        "outputId": "ada1c94f-01d9-45fc-b4a2-ae845f550ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "engish target <bos> A worker taking a reading on a subway train . <eos>\n",
            "german input <bos> Ein Arbeiter liest in einem U-Bahn-Zug . <eos>\n"
          ]
        }
      ],
      "source": [
        "print(\"engish target\",index_to_eng(tgt))\n",
        "print(\"german input\",index_to_german(src))"
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2858e0f2-2e87-47f9-b957-82e9b1439e77"
      },
      "source": [
        "You will find the number of tokens in the German sample:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5af827e7-2ad1-4262-b62e-cf4737c9fa9c",
        "outputId": "17c84103-2b1e-4c19-c208-66546db9dd40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "num_tokens = src.shape[0]\n",
        "num_tokens"
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24e6ae10-fc0d-4249-bd59-7f8863ca17de"
      },
      "source": [
        "You can construct a mask to delineate which inputs are factored into the attention computation. Given that this pertains to a translation task, all tokens in the source sequence are accessible, thus setting the mask values to `false`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d03ab8e3-5382-4af5-a8a7-3ecc96ddd88f",
        "outputId": "4fd85447-61a5-4842-9b64-62d21ec19c0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(DEVICE )\n",
        "src_mask[0:10]"
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a255211-11f4-4c2e-9f21-1d1d3ccf6f20"
      },
      "source": [
        "\n",
        "\n",
        "Extract the first sample from the batch of sequences slated for translation. While currently redundant, this procedure will become relevant later as you handle larger batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "652a4c70-f023-4973-a4d9-f8f18d720633",
        "outputId": "51e7fd1f-f566-4d6e-e2a6-78a7649e8511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 1])\n",
            "torch.Size([9, 1])\n"
          ]
        }
      ],
      "source": [
        "src_=src[:,0].unsqueeze(1)\n",
        "print(src_.shape)\n",
        "print(src.shape)"
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e417af0-ac7c-4286-b450-ba7376c1cee7"
      },
      "source": [
        "Feed the tokens of the sequences designated for translation into the transformer, accompanied by the mask. The resultant values, stored in the 'memory', are the embeddings derived from the output of the transformer encoder as shown in the following image:\n",
        "\n",
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/Transformersencoder.png\" alt=\"trasfoemr\">\n",
        "\n",
        "The memory, which is the encoder's output, encapsulates the original sequence to be translated and serves as the input for the decoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0a14394-ebe7-4fe7-b9b7-e17186a34bec",
        "outputId": "64232918-e890-4065-9f3a-aa4487e5ac75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9, 1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "memory = transformer.encode(src_, src_mask)\n",
        "memory.shape"
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2147ffeb-2b37-436d-b4d0-bb4d8fc46c87"
      },
      "source": [
        " To indicate the beginning of an output sequence generation, initiate it with the start symbol:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e92b1328-3e26-48d9-866d-0be0ca6dd517",
        "outputId": "0d1bd560-5b2d-4e42-97c7-37890f708bbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "ys = torch.ones(1, 1).fill_(BOS_IDX).type(torch.long).to(DEVICE)\n",
        "ys"
      ],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d6f3b95-521a-443a-bf4a-33f4ae11350b"
      },
      "source": [
        "Due to some naming conventions, the term \"target\" is used to denote the prediction. In this context, the \"target\" refers to the words following the current prediction. These can be combined with the source to make further predictions. Consequently, you construct a target mask set to 'false' indicating that no values should be ignored:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ad93451-6d44-47da-94bf-fd74d17a793d",
        "outputId": "e77ba23e-8311-491a-861f-fdb3ebe9d1c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(DEVICE)\n",
        "tgt_mask"
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a086756c-2ad1-48c5-89d6-7cdab5896a05"
      },
      "source": [
        "You feed the encoder's output (referred to as 'memory') and the previous prediction from the transformer, which at this point is solely the start token, into the decoder:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4f49364-cfc1-43ef-936e-c16d41028c73",
        "outputId": "a3c3a406-d552-4f62-b7aa-0e5c81cee6e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "out = transformer.decode(ys, memory, tgt_mask)\n",
        "out.shape"
      ],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd894add-b0a4-43a8-9e8f-8562a6eabddf"
      },
      "source": [
        "The decoder's output is an enhanced word embedding representing the anticipated translation. At this point, the batch dimension is omitted.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5cecb6e-7662-4ac3-9e3a-1215c12dd6eb",
        "outputId": "71984948-9105-46d1-b95d-c8cf8afabf70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "out = out.transpose(0, 1)\n",
        "out.shape"
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a204f3a-2b2f-49ff-84e9-a1d2e367e4c9"
      },
      "source": [
        "Once the decoder produces its output, it's passed through output layer logit value  over the vocabulary of 10837 words. Later on you will only need the last token so you can input```out[:, -1]```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08972e36-c02a-4c5e-87a7-f275d54b9a19",
        "outputId": "9eeb0096-933f-438d-a6ef-612ae3bd626a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10837])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "logit = transformer.generator(out[:, -1])\n",
        "logit.shape"
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64c86763-1c64-42e8-a25f-aef411475d27"
      },
      "source": [
        "The process is succinctly illustrated in the image below:\n",
        "\n",
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/decoder_start.png\" alt=\"trasfoemr\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c833d2ca-c8ff-4bf7-ad18-020507d6caf0"
      },
      "source": [
        "\n",
        "The predicted word is determined by identifying the highest logit value, which signifies the model's most probable translation for the input at a specific position; this position corresponds to the index of the next token.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b9f54ae-5d52-4aeb-8372-a3417ac4a5f7"
      },
      "outputs": [],
      "source": [
        "  _, next_word_index = torch.max(logit, dim=1)"
      ],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2a75d66-72b3-4dee-8029-8515f5b3f888",
        "outputId": "c4319ca2-4fa6-4afb-b96b-39a5724f9dc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "engish output: A\n"
          ]
        }
      ],
      "source": [
        "print(\"engish output:\",index_to_eng(next_word_index))"
      ],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c838867-68f9-4f3f-a957-8a5607f6bf9c"
      },
      "source": [
        "You only need the integer for the index:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8443a8ec-3182-44ad-8461-03da2601582e",
        "outputId": "4049c00c-5483-4429-e768-7d8e2e0e08bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "next_word_index=next_word_index.item()\n",
        "next_word_index"
      ],
      "execution_count": 30
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9bb2249-2e48-4a83-94c8-01f21c4bfed8"
      },
      "source": [
        "Now, append the newly predicted word to the prior predictions, allowing the model to consider the entire sequence of generated words when making its next prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f76904b-845d-4058-8ef1-fd35a85cbbd5",
        "outputId": "f3802292-5bd1-4e40-a66d-bb5c565a10fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [6]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word_index)], dim=0)\n",
        "ys"
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49aa360-0823-4e2b-88b5-ccbba1706a1f"
      },
      "source": [
        "To predict the subsequent word in the translation, update target mask and use the transformer decoder to derive the word probabilities. The word with the maximum probability is then selected as the prediction. Note that the encoder output contains all the information you need.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8db2f4cc-35bf-4d2b-857f-cbfa783ac082",
        "outputId": "cf6fa98a-bc5d-4940-a4ca-e340bdaaf661"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True],\n",
              "        [False, False]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Update the target mask for the current sequence length.\n",
        "tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(DEVICE)\n",
        "tgt_mask"
      ],
      "execution_count": 32
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8288f720-e66c-4e52-a89b-af55084569b1",
        "outputId": "264d87ea-ee99-4bf2-ba5c-76d085968930"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Decode the current sequence using the transformer and retrieve the output.\n",
        "out = transformer.decode(ys, memory, tgt_mask)\n",
        "out = out.transpose(0, 1)\n",
        "out.shape"
      ],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f88a29e-7b8d-407a-b560-bfa6a82c745d",
        "outputId": "13a75ce1-3528-4b9c-ac9d-93d744dfc296"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "out[:, -1].shape"
      ],
      "execution_count": 34
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab6630b2-8922-4486-aa21-d5cf9e5bd9a4",
        "outputId": "0c761dba-c080-4d29-b6ca-8114f7462c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English output: worker\n"
          ]
        }
      ],
      "source": [
        "# Get the word probabilities for the last predicted word.\n",
        "prob = transformer.generator(out[:, -1])\n",
        "# Find the word index with the highest probability.\n",
        "_, next_word_index = torch.max(prob, dim=1)\n",
        "# Print the predicted English word.\n",
        "print(\"English output:\", index_to_eng(next_word_index))\n",
        "# Convert the tensor value to a Python scalar.\n",
        "next_word_index = next_word_index.item()"
      ],
      "execution_count": 35
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55d1b364-a53e-4673-81cb-7b710c901981"
      },
      "source": [
        "Now, update the prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a0c8ca1-62f3-467c-9cdd-fefdcefb65a4",
        "outputId": "cd5008f8-089f-4f9f-e3f1-9545088d69a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "engish output <bos> A worker\n"
          ]
        }
      ],
      "source": [
        "ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word_index)], dim=0)\n",
        "print(\"engish output\",index_to_eng(ys))"
      ],
      "execution_count": 36
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0682f694-5f1c-409b-8bfc-eec981ac31db"
      },
      "source": [
        "The process can be summarized as follows:\n",
        "Starting with the initial output of the encoder and the <BOS> token, the decoder's output is looped back into the decoder until the translated sequence is fully decoded. This cycle continues until the length of the new translated sequence matches that of the original sequence. As shown in the following image, the function ```greedy_decode``` is also included.\n",
        "    \n",
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/decoder.png\" alt=\"trasfoemr\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0762a49e-0a55-41dc-8202-9695ec166f8e"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys"
      ],
      "execution_count": 37
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2742b78-5db0-4819-bcd7-8938ccac7a07"
      },
      "source": [
        "Retrieve the indices for the German language and generate the corresponding mask:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a5cbe73-ef61-4e02-a5db-0d1fd2f45bcd"
      },
      "outputs": [],
      "source": [
        "src\n",
        "src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(DEVICE )"
      ],
      "execution_count": 38
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57c53a7f-cfeb-46ae-9575-b1a31ac63c10"
      },
      "source": [
        "Set a reasonable value for the max length of target sequence:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80019b7b-a456-42b7-beff-482e18c79686",
        "outputId": "9746f542-c0ca-47c5-aba7-86f5d4ff6ea5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "max_len=src.shape[0]+5\n",
        "max_len"
      ],
      "execution_count": 39
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ff4c6d8-2f1f-493a-be1b-345d14674e74"
      },
      "source": [
        "Apply the function ```greedy_decode``` to data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3eef9df-d228-4148-88d2-b3d72e5b3252",
        "outputId": "7bd66c73-4d08-4277-9988-d0674c7cc3ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "engish  <bos> A worker is reading a newspaper in a train . <eos>\n"
          ]
        }
      ],
      "source": [
        "ys=greedy_decode(transformer, src, src_mask, max_len, start_symbol=BOS_IDX)\n",
        "print(\"engish \",index_to_eng(ys))"
      ],
      "execution_count": 40
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4adf6f0-ce59-4920-a2fd-bd8d60e3b8a9"
      },
      "source": [
        "Notice that it works, but it's not exactly the same. However, it's still pretty good.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d28dc11-bbf2-44cc-8eac-65fdf6bb8bdf",
        "outputId": "73f14ecd-2fab-4ef2-b057-55633709ff09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "engish  <bos> A worker taking a reading on a subway train . <eos>\n"
          ]
        }
      ],
      "source": [
        "print(\"engish \",index_to_eng(tgt))"
      ],
      "execution_count": 41
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40cba568-c89f-463a-a125-ea4ca93841cd"
      },
      "source": [
        "### Decoding the differences: Training vs. inference in neural machine translation\n",
        "\n",
        "During the inference phase, when the model is deployed for actual translation tasks, the decoder generates the sequence without access to the expected target sequence. Instead, it bases its predictions on the encoder's output and the tokens it has produced in sequence so far. The process is autoregressive, with the decoder continually predicting the next token until it outputs an end-of-sequence token, indicating the translation is complete.\n",
        "\n",
        "The key difference between the training and inference stages lies in the inputs to the decoder. During training, the decoder benefits from exposure to the ground truth--receiving the exact target sequence tokens incrementally through a technique known as \"teacher forcing.\" This approach is in stark contrast to some other neural network architectures that rely on the network's previous predictions as inputs during training. Once training concludes, the datasets used resemble those employed in more conventional neural network models, providing a familiar foundation for comparison and evaluation.\n",
        "\n",
        "First, import `CrossEntropyLoss` loss and create a Cross Entropy Loss object The loss will  not be calculated when the token with index `PAD_IDX` an input.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16850b2f-6d6b-43b1-8591-545d17ded070"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "loss_fn = CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": 42
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06a06778-b61f-4c3a-b4e8-cac5a095a907"
      },
      "source": [
        "Drop the last sample of the target\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9181142-e285-472d-a5a2-eef7bff8805b",
        "outputId": "1a110a4d-5e55-4c4c-d2f5-b1c7634b43b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bos> A worker taking a reading on a subway train .\n",
            "<bos> A worker taking a reading on a subway train . <eos>\n"
          ]
        }
      ],
      "source": [
        "tgt_input = tgt[:-1, :]\n",
        "print(index_to_eng(tgt_input))\n",
        "print(index_to_eng(tgt))"
      ],
      "execution_count": 43
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb2fc76d-ce38-4653-8074-420589ceb9fd"
      },
      "source": [
        "Create the required masks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fb99aa2-dded-4a27-ab33-51c956a7c2f3",
        "outputId": "e282dbce-8526-48f2-d47b-2551a537f4af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of src_mask: torch.Size([9, 9])\n",
            "Shape of tgt_mask: torch.Size([11, 11])\n",
            "Shape of src_padding_mask: torch.Size([1, 9])\n",
            "Shape of tgt_padding_mask: torch.Size([1, 11])\n"
          ]
        }
      ],
      "source": [
        "src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "print(f\"Shape of src_mask: {src_mask.shape}\")\n",
        "print(f\"Shape of tgt_mask: {tgt_mask.shape}\")\n",
        "print(f\"Shape of src_padding_mask: {src_padding_mask.shape}\")\n",
        "print(f\"Shape of tgt_padding_mask: {tgt_padding_mask.shape}\")"
      ],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b225ce4-81e9-45fe-b27c-efe9d6831517",
        "outputId": "bac210a0-b798-4c85-aa6d-9b589b2ab40c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False, False, False, False, False, False]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "src_padding_mask"
      ],
      "execution_count": 45
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e3848ff-3ed3-442b-944f-f137bb7cdd38"
      },
      "source": [
        "In the target mask, each subsequent column incrementally reveals more tokens by introducing negative infinity values, thereby unblocking them. You can display the target mask to visualize the progression or specifically identify which tokens are being masked at each step.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7caf7346-ba05-436d-aec2-b46a24f78a67",
        "outputId": "c92fb1d5-c8a3-4abe-bbbc-ea520f18c8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>',\n",
              " '<bos> A',\n",
              " '<bos> A worker',\n",
              " '<bos> A worker taking',\n",
              " '<bos> A worker taking a',\n",
              " '<bos> A worker taking a reading',\n",
              " '<bos> A worker taking a reading on',\n",
              " '<bos> A worker taking a reading on a',\n",
              " '<bos> A worker taking a reading on a subway',\n",
              " '<bos> A worker taking a reading on a subway train',\n",
              " '<bos> A worker taking a reading on a subway train .']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "print(tgt_mask)\n",
        "[index_to_eng( tgt_input[t==0])  for t in tgt_mask] #index_to_eng(tgt_input))"
      ],
      "execution_count": 46
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "656a2ea2-a7af-421a-bb9a-6b91727e162e"
      },
      "source": [
        "When you call `model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask)`,  the forward method of the `Seq2SeqTransformer` class. This process generates logits for the target sequence, which can then be translated into actual tokens by taking the highest probability prediction at each step in the sequence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d24b591-45c3-4329-bea7-b65f20d144db"
      },
      "source": [
        "## Loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cefaedc-8d5e-4c36-a103-df7679b277d7"
      },
      "source": [
        "Let's delve into how you can calculate the loss, you have your  ```src``` and  ```tgt_input```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f50dd55-e45e-4704-b3f2-a7f3234da863",
        "outputId": "2fc14acb-ba5d-43c0-f90b-90b3b04db227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output shape torch.Size([11, 1, 10837])\n",
            "target shape torch.Size([11, 1])\n",
            "source shape  torch.Size([9, 1])\n"
          ]
        }
      ],
      "source": [
        "logits = transformer(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "print(\"output shape\",logits.shape)\n",
        "print(\"target shape\",tgt_input.shape)\n",
        "print(\"source shape \",src.shape)"
      ],
      "execution_count": 47
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8a2f27a-9169-469b-9bf2-f0a2c29defa7"
      },
      "source": [
        "\n",
        "During the training phase, an intriguing and sophisticated aspect of the process is the dual functionality of the target. It simultaneously acts as the input for the transformer's decoder and as the standard against which the prediction's accuracy is measured.  For clarity in the discussions, you'll refer to the target used as the input for the decoder as the \"Input to the Decoder.\" On the other hand, the \"Ground Truth for Prediction,\" which is a the target sequence shifted to the right, as it's an auto regressive model. This will be simply known as the \"Target out\" moving forward.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "185c2fa3-d122-407d-a448-06174c0e1037"
      },
      "source": [
        "Ground Truth for Prediction is simply shifted right and is called ```tgt_out``` , you can print out tokens:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22951870-51d6-4151-a814-c7b4b60a188f",
        "outputId": "5de690ac-9189-4146-cf90-c47a0245b150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'worker',\n",
              " 'taking',\n",
              " 'a',\n",
              " 'reading',\n",
              " 'on',\n",
              " 'a',\n",
              " 'subway',\n",
              " 'train',\n",
              " '.',\n",
              " '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "tgt_out = tgt[1:, :]\n",
        "print(tgt_out.shape)\n",
        "[index_to_eng(t)  for t in tgt_out]"
      ],
      "execution_count": 48
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58c5b4bc-c4ae-4d6f-af55-381092bd4f50"
      },
      "source": [
        "\n",
        "The token indices represent the classes you aim to predict. By flattening the tensor, each index becomes a distinct sample, serving as the target for the cross-entropy loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbe145d2-9e1f-4d60-bf53-4d7cdb3c1e1d",
        "outputId": "e0416b8d-9374-4f23-820e-9cbd31f9a508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  6, 348, 168,   4, 217,   9,   4, 369, 240,   5,   3],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "tgt_out_flattened = tgt_out.reshape(-1)\n",
        "print(tgt_out_flattened.shape)\n",
        "tgt_out_flattened"
      ],
      "execution_count": 49
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "152ffd44-e5ed-4d7f-94b9-9d996030fb5d"
      },
      "source": [
        "In this autoregressive model,  showcase the input target tokens after the application of the mask. Beside them, you can display the target output, illustrating how the model adeptly predicts past values based on present ones. This clear visualization highlights the model's capability to use current information to infer what has preceded, a key feature of its autoregressive nature.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c780bd4-9bba-4638-a0ad-9670ccee2f94",
        "outputId": "6d0a5a39-bbea-485f-819f-9c72b067d145"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['input: <bos> target: A',\n",
              " 'input: <bos> A target: worker',\n",
              " 'input: <bos> A worker target: taking',\n",
              " 'input: <bos> A worker taking target: a',\n",
              " 'input: <bos> A worker taking a target: reading',\n",
              " 'input: <bos> A worker taking a reading target: on',\n",
              " 'input: <bos> A worker taking a reading on target: a',\n",
              " 'input: <bos> A worker taking a reading on a target: subway',\n",
              " 'input: <bos> A worker taking a reading on a subway target: train',\n",
              " 'input: <bos> A worker taking a reading on a subway train target: .',\n",
              " 'input: <bos> A worker taking a reading on a subway train . target: <eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "[\"input: {} target: {}\".format(index_to_eng( tgt_input[m==0]),index_to_eng( t))  for m,t in zip(tgt_mask,tgt_out)]"
      ],
      "execution_count": 50
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44c6e3b3-5878-424d-8788-c44264b895c9"
      },
      "source": [
        "Now, calculate the loss as the output from the transformer's decoder is provided as input to the cross-entropy loss function along with the target sequence values. Given that the transformer's output has the dimensions sequence length, batch size, and features (vocab_size), it's necessary to reshape this output to align with the standard input format required by the cross-entropy loss function. This step ensures that the loss is calculated correctly, comparing the predicted sequence against the ground truth at each time step across the batch using the reshape method\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebd80e22-7314-412d-b81c-339812d92e72",
        "outputId": "98419602-a90b-4495-a78f-88df73089598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7483, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "print(loss)"
      ],
      "execution_count": 51
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa48c4e1-a590-48c2-a5db-8c682b5e6b3c"
      },
      "source": [
        "### Under the hood of loss calculation (Optional)\n",
        "That's it for loss calculation, but if you are curious how the loss is calculated here is what happens under the hood of calculating the Cross Entropy loss. First, check the shape of tensors before and after the reshaping:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c62c758-4b1e-4cd4-b2af-7a5d7ea5e903",
        "outputId": "59894ba6-9ed2-493e-c744-10bb2b03a37d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logit's shape is: torch.Size([11, 1, 10837])\n",
            "logit_flat's shape is: torch.Size([11, 10837])\n",
            "tgt_out's shape is: torch.Size([11, 1])\n",
            "tgt_out_flat's shape is: torch.Size([11])\n"
          ]
        }
      ],
      "source": [
        "# logits.reshape(-1, logits.shape[-1]) reshapes the logits tensor to a 2D tensor with a shape of [sequence_length * batch_size, vocab_size]. This reshaping is done to align both the predicted logits and target outputs for the loss calculation.\n",
        "print(\"logit's shape is:\",logits.shape)\n",
        "logits_flattened = logits.reshape(-1, logits.shape[-1])\n",
        "print(\"logit_flat's shape is:\",logits_flattened.shape)\n",
        "\n",
        "\n",
        "# tgt_out.reshape(-1) reshapes the tgt_out tensor to a 1D tensor by flattening it along the sequence and batch dimensions. This is done to align it with the reshaped logits.\n",
        "print(\"tgt_out's shape is:\",tgt_out.shape)\n",
        "tgt_out_flattened = tgt_out.reshape(-1)\n",
        "print(\"tgt_out_flat's shape is:\",tgt_out_flattened.shape)\n"
      ],
      "execution_count": 52
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "846bbf83-e96a-49c3-b99a-d3b32121c5de"
      },
      "source": [
        "Inside the loss function, logits will transform into probabilities between [0,1] that sum up to 1:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6a670ab-a60e-473f-8b7d-45f7916f6cb7",
        "outputId": "827e7136-7636-430d-a561-8b641cfe311a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000, device='cuda:0', grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Applying the Cross-Entropy Loss Function\n",
        "probs = torch.nn.functional.softmax(logits_flattened, dim=1)\n",
        "probs[1].sum()"
      ],
      "execution_count": 53
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94c0f8af-ae32-41f1-9b18-5842ca231377"
      },
      "source": [
        "let's check the probabilities for some random tokens:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de9dd8c8-606c-41b7-a117-2182e2583283",
        "outputId": "488ad382-098c-452c-ba77-fe4746cb3eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted token id: 6 predicted probaility: 0.9196327924728394\n",
            "Actual token id: 6 predicted probaility: 0.9196327924728394 \n",
            "\n",
            "Predicted token id: 348 predicted probaility: 0.8191961050033569\n",
            "Actual token id: 348 predicted probaility: 0.8191961050033569 \n",
            "\n",
            "Predicted token id: 10 predicted probaility: 0.6045702695846558\n",
            "Actual token id: 168 predicted probaility: 2.3911841708468273e-05 \n",
            "\n",
            "Predicted token id: 4 predicted probaility: 0.8544505834579468\n",
            "Actual token id: 4 predicted probaility: 0.8544505834579468 \n",
            "\n",
            "Predicted token id: 285 predicted probaility: 0.3047475218772888\n",
            "Actual token id: 217 predicted probaility: 0.018344080075621605 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range (5):\n",
        "    # using argmax, you can retrieve the index of the token that is predicted with the highest probaility\n",
        "    print(\"Predicted token id:\",probs[i].argmax().item(), \"predicted probaility:\",probs[i].max().item())\n",
        "    # you can also check the actual token from the tgt_out_flat\n",
        "    print(\"Actual token id:\",tgt_out_flattened[i].item(), \"predicted probaility:\", probs[i,tgt_out_flattened[i]].item(),\"\\n\")"
      ],
      "execution_count": 54
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0cd0cce-5912-4c43-a1df-9b96ef4ef0fd"
      },
      "source": [
        "It can be seen that for many tokens the model is doing a good job in predicting the token, while for some of the tokens(for example the third block in the output above) the model is not assigning a high probability to the actual token to be predicted. The difference between the predicted probability for such tokens is the reason why the loss would not sum up to 0.\n",
        "\n",
        "Now, you can proceed with calculating the difference between the actual token's probability (1) and the predicted probabilities for each token:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ce18e6a-8bf8-4954-87a1-4e0be1465c4b",
        "outputId": "69baa368-f2d0-4bbe-ffa5-f87bc3838044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: -0.6076890826225281\n"
          ]
        }
      ],
      "source": [
        "neg_log_likelihood = torch.nn.functional.nll_loss(probs, tgt_out_flattened)\n",
        "# Step 3: Obtaining the Loss Value\n",
        "loss = neg_log_likelihood\n",
        "\n",
        "# Print the total loss value\n",
        "print(\"Loss:\", loss.item())"
      ],
      "execution_count": 55
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7eda021-1ef4-400c-bfd0-043219de24a3"
      },
      "source": [
        "## Evaluate\n",
        "By following the aforementioned procedures, you can develop a function that is capable of making predictions and subsequently computing the corresponding loss on the validation data, you will use this function later on.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e9973a6-2860-460b-909d-abcc1d852f1a"
      },
      "outputs": [],
      "source": [
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(val_dataloader))"
      ],
      "execution_count": 56
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb2d0589-3865-41f0-8e6a-aa4ea7517014"
      },
      "source": [
        "# Training the model\n",
        "Incorporating the previously outlined steps, proceed to train the model. Apart from these specific procedures, the overall training process conforms to the conventional methods employed in neural network training. Now, write a function to train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06de1480-8f43-4752-b795-9b52d183f04c"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, optimizer, train_dataloader):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "\n",
        "    # Wrap train_dataloader with tqdm for progress logging\n",
        "    train_iterator = tqdm(train_dataloader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for src, tgt in train_iterator:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "        src_mask = src_mask.to(DEVICE)\n",
        "        tgt_mask = tgt_mask.to(DEVICE)\n",
        "        src_padding_mask = src_padding_mask.to(DEVICE)\n",
        "        tgt_padding_mask = tgt_padding_mask.to(DEVICE)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "        logits = logits.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "        # Update tqdm progress bar with the current loss\n",
        "        train_iterator.set_postfix(loss=loss.item())\n",
        "\n",
        "    return losses / len(list(train_dataloader))"
      ],
      "execution_count": 57
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84826a74-4cf2-483b-9cc5-3733124526de"
      },
      "source": [
        "The configuration for the translation model includes a source and target vocabulary size determined by the dataset languages, an embedding size of 512, 8 attention heads, a hidden dimension for the feed-forward network of 512, and a batch size of 128. The model is structured with three layers each in both the encoder and the decoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7afeb94d-05e1-4002-a7bd-b9d2dde1df90"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3"
      ],
      "execution_count": 58
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a3a9cd3-5683-4830-aeb8-03e7caa08bdb"
      },
      "source": [
        "Create a train loader with a batch size of 128.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adae8c16-a93a-4051-9d89-c9dfe40178dd"
      },
      "outputs": [],
      "source": [
        "train_dataloader, val_dataloader = get_translation_dataloaders(batch_size = BATCH_SIZE)"
      ],
      "execution_count": 59
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a64b59c-0fbd-486a-bbba-a413f8ea1ec2"
      },
      "source": [
        "Create a transformer model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b6ec9e9-fcf1-4b81-af5b-36a8201184fe"
      },
      "outputs": [],
      "source": [
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "transformer = transformer.to(DEVICE)"
      ],
      "execution_count": 60
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "885ec650-98d2-4521-943b-df2b8411e39e"
      },
      "source": [
        "Initialize the weights of the transformer model. Insulate the Adam optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7d1aacf-dc9a-4a6e-9856-53f8904a01c5"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "execution_count": 61
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4438a024-c5fe-458f-b32a-e5d52392ebb7"
      },
      "source": [
        "Initialize the train loss and validation loss list.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "343c14a4-dd40-4519-8632-8041766c8dc4"
      },
      "outputs": [],
      "source": [
        "TrainLoss=[]\n",
        "ValLoss=[]"
      ],
      "execution_count": 62
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a116c441-c3eb-4061-b6ac-16244bf0c731",
        "outputId": "6349ac29-b0a5-4f4a-c7bb-a5b9bef9bf12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 5.079, Val loss: 4.388, Epoch time = 20.263s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Train loss: 3.881, Val loss: 3.854, Epoch time = 20.064s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Train loss: 3.488, Val loss: 3.601, Epoch time = 19.738s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, Train loss: 3.231, Val loss: 3.411, Epoch time = 19.711s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Train loss: 3.036, Val loss: 3.264, Epoch time = 19.990s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6, Train loss: 2.877, Val loss: 3.147, Epoch time = 19.802s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7, Train loss: 2.742, Val loss: 3.059, Epoch time = 19.659s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8, Train loss: 2.624, Val loss: 2.954, Epoch time = 19.826s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9, Train loss: 2.518, Val loss: 2.868, Epoch time = 19.475s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Train loss: 2.420, Val loss: 2.817, Epoch time = 19.528s\n"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(transformer, optimizer, train_dataloader)\n",
        "    TrainLoss.append(train_loss)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    ValLoss.append(val_loss)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "torch.save(transformer.state_dict(), 'transformer_de_to_en_model.pt')"
      ],
      "execution_count": 63
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "08ff61b8-862c-4833-bcae-b12da486faa5",
        "outputId": "b009e926-9bb4-4602-d608-ddfcd02a3748"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs = range(1, len(TrainLoss) + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, TrainLoss, 'r', label='Training loss')\n",
        "plt.plot(epochs,ValLoss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 64
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17c77977-45e8-4424-845d-4406355895f9"
      },
      "source": [
        "## Translation and evaluation\n",
        "Using the greedy_decode function that you defined earlier, you can create a translator function that generates English translation of an input German text.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8dce4af-90df-493c-a986-b34f8ae518c1"
      },
      "outputs": [],
      "source": [
        "# translate input sentence into target language\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ],
      "execution_count": 66
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29ff29dc-ac12-4b4b-979d-1429b7396886",
        "outputId": "9aa932a0-68c3-4e11-debf-d23c591a57f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German Sentence:  Männer stehen neben irgendeiner hydraulischen Maschine . \n",
            "English Translation:  Men are standing next to some sort of hydraulic machine . \n",
            "Model Translation:  Men are standing next to a basketball next to a basketball player in white shirt next to the ocean\n",
            "_________\n",
            "\n",
            "German Sentence:  Zwei Arbeiter reinigen nachts ein Bauwerk . \n",
            "English Translation:  Two workers are cleaning a structure at night . \n",
            "Model Translation:  Two workers are throwing a small boat near a small water . \n",
            "_________\n",
            "\n",
            "German Sentence:  Sieben Bauarbeiter arbeiten an einem Gebäude . \n",
            "English Translation:  Seven construction workers working on a building . \n",
            "Model Translation:  Construction workers work on a building working on a building working on a building working on a building .\n",
            "_________\n",
            "\n",
            "German Sentence:  Die Kinder spielen nachts mit Wunderkerzen . \n",
            "English Translation:  The children play with sparklers at night . \n",
            "Model Translation:  The children are playing with a green shirt of green t - shirt is playing with long white children\n",
            "_________\n",
            "\n",
            "German Sentence:  Ein älteres Paar geht zusammen spazieren . \n",
            "English Translation:  An older couple taking a walk together . \n",
            "Model Translation:  A couple walks together in a park , holding a young couple walking together . \n",
            "_________\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for n in range(5):\n",
        "    german, english= next(data_itr)\n",
        "\n",
        "    print(\"German Sentence:\",index_to_german(german).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
        "    print(\"English Translation:\",index_to_eng(english).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
        "    print(\"Model Translation:\",translate(transformer,index_to_german(german)))\n",
        "    print(\"_________\\n\")"
      ],
      "execution_count": 67
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16bd9c61-6356-4a5a-8b3e-946cfcd9e926"
      },
      "source": [
        "### Evaluation with BLEU score\n",
        "The BLEU score provides a quantitative measure of translation accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93a78f75-31d2-488b-88a1-9eb92fd6d039"
      },
      "outputs": [],
      "source": [
        "def calculate_bleu_score(generated_translation, reference_translations):\n",
        "    # convert the generated translations and reference translations into the expected format for sentence_bleu\n",
        "    references = [reference.split() for reference in reference_translations]\n",
        "    hypothesis = generated_translation.split()\n",
        "\n",
        "    # calculate the BLEU score\n",
        "    bleu_score = sentence_bleu(references, hypothesis)\n",
        "\n",
        "    return bleu_score"
      ],
      "execution_count": 68
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73b004d2-eeae-4510-ac84-2b4ddfaa18ea",
        "outputId": "dc10a792-ca3a-4d01-a914-a7b15f64fa74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.529018057265134 for  A brown dog plays in the snow in the snow playing in the\n"
          ]
        }
      ],
      "source": [
        "generated_translation = translate(transformer,\"Ein brauner Hund spielt im Schnee .\")\n",
        "\n",
        "reference_translations = [\n",
        "    \"A brown dog is playing in the snow .\",\n",
        "    \"A brown dog plays in the snow .\",\n",
        "    \"A brown dog is frolicking in the snow .\",\n",
        "    \"In the snow, a brown dog is playing .\"\n",
        "\n",
        "]\n",
        "\n",
        "bleu_score = calculate_bleu_score(generated_translation, reference_translations)\n",
        "print(\"BLEU Score:\", bleu_score, \"for\",generated_translation)"
      ],
      "execution_count": 69
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "prev_pub_hash": "f583ab330d392f3fbc803e1d84830f575a94e0d7cc0f8b3af49ded45fd51cc14",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}